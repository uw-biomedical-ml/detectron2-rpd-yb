{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import detectron2\n",
    "from detectron2.data import DatasetCatalog,MetadataCatalog\n",
    "from plain_train_net import grab_dataset\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.engine import launch\n",
    "\n",
    "\n",
    "reprocess_results=True\n",
    "# dataset_name = \"reserves_fold1\"\n",
    "dataset_name = \"Test Set\"\n",
    "dpi=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE_PER_IMAGE: 512\n",
      "IN_FEATURES:\n",
      "- p2\n",
      "- p3\n",
      "- p4\n",
      "- p5\n",
      "IOU_LABELS:\n",
      "- 0\n",
      "- 1\n",
      "IOU_THRESHOLDS:\n",
      "- 0.5\n",
      "NAME: StandardROIHeads\n",
      "NMS_THRESH_TEST: 0.01\n",
      "NUM_CLASSES: 1\n",
      "POSITIVE_FRACTION: 0.25\n",
      "PROPOSAL_APPEND_GT: true\n",
      "SCORE_THRESH_TEST: 0.001\n",
      "\n",
      "detectron2://ImageNetPretrained/FAIR/X-101-32x8d.pkl\n",
      "./output\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "from detectron2.config import get_cfg\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('configs/working.yaml')\n",
    "#really low iou for nms in order to separate out lesions\n",
    "# cfg.merge_from_list([\"MODEL.WEIGHTS\", \"output_valid_fold1/model_final.pth\",\n",
    "#                      \"OUTPUT_DIR\", \"output_valid_\"+ dataset_name + \"/results\"])\n",
    "#print(cfg.dump())  # print formatted configs\n",
    "print(cfg.MODEL.ROI_HEADS.dump())\n",
    "print(cfg.MODEL.WEIGHTS)\n",
    "print(cfg.OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [dataset_name]:\n",
    "    try:\n",
    "        DatasetCatalog.register(name, grab_dataset(name))\n",
    "    except:\n",
    "        print('Already registered.')\n",
    "        #do nothing\n",
    "    MetadataCatalog.get(name).thing_classes = [\"rpd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%script false --no-raise-error\n",
    "#os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "#from torch.nn.parallel import DistributedDataParallel\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "#from plain_train_net import EvaluateClass\n",
    "from detectron2.evaluation import inference_on_dataset, COCOEvaluator\n",
    "\n",
    "def predict_func(cfg,dataset_name):\n",
    "    model = build_model(cfg)  # returns a torch.nn.Module\n",
    "    \n",
    "    # distributed = comm.get_world_size() > 1\n",
    "    # if distributed:\n",
    "    #     model = DistributedDataParallel(\n",
    "    #         model, device_ids=[comm.get_local_rank()], broadcast_buffers=False\n",
    "    #     )\n",
    "    \n",
    "    myloader = build_detection_test_loader(cfg,dataset_name) \n",
    "    myeval = COCOEvaluator(dataset_name,tasks={'bbox','segm'},output_dir =\"output_\"+ dataset_name) #produces _coco_format.json when initialized\n",
    "\n",
    "\n",
    "    for mdl in (\"fold1\", \"fold2\", \"fold3\", \"fold4\",\"fold5\"):\n",
    "        #build model\n",
    "        model_weights_path = \"/data/amd-data/cera-rpd/detectron2-rpd/output_valid_\"+ mdl +\"/model_final.pth\"\n",
    "        DetectionCheckpointer(model).load(model_weights_path);  # load a file, usually from cfg.MODEL.WEIGHTS\n",
    "        model.eval(); #set model in evaluation mode\n",
    "        myeval.reset()\n",
    "        output_dir = \"output_\"+ dataset_name + \"/\"+mdl\n",
    "        myeval._output_dir = output_dir\n",
    "        print(\"running inference on \", mdl)\n",
    "        results_i = inference_on_dataset(model, myloader, myeval) #produces coco_instance_results.json when myeval.evaluate is called\n",
    "    \n",
    "    return  \n",
    "predict_func(cfg,dataset_name)\n",
    "print(\"done predict_func\")\n",
    "# launch(\n",
    "#     predict_func,\n",
    "#     6, # of gpus\n",
    "#     num_machines=1,\n",
    "#     machine_rank=0,\n",
    "#     dist_url=\"auto\",\n",
    "#     args=(cfg,dataset_name,), #args to predict_func\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Test Set/fold1/coco_instances_results.json into memory. 31392 instance detected.\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Test Set/fold2/coco_instances_results.json into memory. 29391 instance detected.\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Test Set/fold3/coco_instances_results.json into memory. 32281 instance detected.\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Test Set/fold4/coco_instances_results.json into memory. 26330 instance detected.\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Test Set/fold5/coco_instances_results.json into memory. 30312 instance detected.\n",
      "\n",
      "Working with 5 models, 1 categories, and 13813 images.\n",
      "Computing mean score non-max suppression ensembling for 13813 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 268/13813 [00:02<02:30, 90.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39464/3884961349.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mEnsembler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnsembler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnsembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fold1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fold2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fold3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fold4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fold5\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_score_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ssong/detectron2-rpd-yb/Ensembler.py\u001b[0m in \u001b[0;36mmean_score_nms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mobj_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#a set of objects (frozensets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoco_dt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#for each detector append predictions to df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgToAnns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#for each category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/detectron/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   8968\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8969\u001b[0m                 \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8970\u001b[0;31m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8971\u001b[0m             )\n\u001b[1;32m   8972\u001b[0m         ).__finalize__(self, method=\"append\")\n",
      "\u001b[0;32m~/miniconda3/envs/detectron/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/detectron/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/detectron/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# figure out what our result ndim is going to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "from Ensembler import Ensembler\n",
    "ens = Ensembler('output_'+dataset_name,dataset_name,[\"fold1\", \"fold2\", \"fold3\", \"fold4\",\"fold5\"],.2)\n",
    "ens.mean_score_nms()\n",
    "ens.save_coco_instances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using previously cached COCO format annotations at 'output_Test Set/Test Set_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Calculated metrics for 13813 images\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=1.18s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      "WARNING: Scores for all iou thresholds and all recall levels are not defined. This can arise if ground truth annotations contain no instances. Leaving fpr matrix as None\n",
      "Using alternate calculation for fpr at instance score threshold of 0.5\n",
      "{'dataset': 'Test Set', 'precision': -1.0, 'recall': 0.0, 'fpr': 0.14775935702037257, 'iou': 0.2, 'probability': 0.5}\n",
      "WARNING: Scores for all iou thresholds and all recall levels are not defined. This can arise if ground truth annotations contain no instances. Leaving fpr matrix as None\n",
      "Using alternate calculation for fpr at instance score threshold of 0.5\n"
     ]
    }
   ],
   "source": [
    "from plain_train_net import EvaluateClass,CreatePlotsRPD\n",
    "import json\n",
    "#evaluate ensemble\n",
    "myeval = EvaluateClass(\n",
    "    dataset_name, \"output_\"+ dataset_name,iou_thresh = .2,prob_thresh=0.5,evalsuper=False)\n",
    "myeval.evaluate()\n",
    "%precision 3\n",
    "print(myeval.summarize_scalars())\n",
    "with open(os.path.join(\"output_\"+ dataset_name,'scalar_dict.json'),\"w\") as outfile:\n",
    "    json.dump(obj=myeval.summarize_scalars(),fp=outfile)\n",
    "#num_images = myeval.num_images\n",
    "#myeval.plot_PRcurve()\n",
    "#plt.tight_layout()\n",
    "#myeval.plot_recall_vs_prob()\n",
    "#plt.tight_layout()\n",
    "\n",
    "RPDplt = CreatePlotsRPD.initfromcoco(myeval.mycoco,myeval.prob_thresh)\n",
    "#RPDplt.gt_dt_FP_FN_count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate individual models\n",
    "import json\n",
    "myeval.evalsuper=False\n",
    "for mdl in (\"fold1\", \"fold2\", \"fold3\", \"fold4\",\"fold5\"):\n",
    "    myeval.reset()\n",
    "    output_dir = \"output_\"+ dataset_name + \"/\"+mdl\n",
    "    myeval._output_dir = output_dir\n",
    "    myeval.evaluate()\n",
    "    print(myeval.summarize_scalars())\n",
    "    with open(os.path.join(output_dir,'scalar_dict.json'),\"w\") as outfile:\n",
    "        json.dump(obj=myeval.summarize_scalars(),fp=outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from table_styles import styles\n",
    "mydicts=[]\n",
    "for mdl in ['fold1','fold2','fold3','fold4','fold5']:\n",
    "    output_dir = \"output_\"+ dataset_name + \"/\"+mdl\n",
    "    with open(os.path.join(output_dir,'scalar_dict.json')) as f:\n",
    "        mydicts.append(json.load(f))\n",
    "with open(os.path.join(\"output_\"+ dataset_name,'scalar_dict.json')) as f:\n",
    "    mydicts.append(json.load(f))\n",
    "dfr = pd.DataFrame(mydicts)\n",
    "dfr = dfr.assign(fp = np.int32(dfr.fpr*num_images))\n",
    "dfr = dfr.assign(f1 = 2*(dfr.precision*dfr.recall)/(dfr.precision + dfr.recall))\n",
    "dfr = dfr.assign(model = ['1','2','3','4','5','ensemble'])\n",
    "# dfr = dfr[['model','fpr','fp','probability','dataset']]\n",
    "dfr = dfr[['model','dataset','precision','recall','f1','fpr','fp','iou','probability']]\n",
    "pd.set_option('display.precision',3)\n",
    "dfr.style.set_table_styles(styles).set_table_attributes('style=\"font-size: 17px\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from plain_train_net import OutputVis\n",
    "\n",
    "dataset_name = 'Fold 1'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "out_file = os.path.join(\"output_\"+ dataset_name,'mean_score_nms_'+dataset_name+'_nonrpd.pdf')\n",
    "\n",
    "# mdl = 'fold1'\n",
    "# pred_file = os.path.join(\"output_\"+ dataset_name,mdl,\"coco_instances_results.json\")\n",
    "# out_file = os.path.join(\"output_\"+ dataset_name,'mean_score_nms_'+mdl+'.pdf')\n",
    "\n",
    "# vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=False)\n",
    "# ImgIds = RPDplt.dfimg.index[RPDplt.dfimg.dt_instances>0] #np.abs(df.gt_xpxs-df.dt_xpxs).sort_values(ascending=False).index[0:50].values\n",
    "# vis.output_to_pdf(ImgIds,out_file)\n",
    "\n",
    "df = RPDplt.dfimg\n",
    "vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=True)\n",
    "ImgIds = RPDplt.dfimg.sample(50).index.values\n",
    "#ImgIds = np.abs(df.gt_xpxs-df.dt_xpxs).sort_values(ascending=False).index[0:10].values\n",
    "vis.output_to_pdf(ImgIds,out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fcddd2",
   "metadata": {},
   "source": [
    "# Creating a TIF file from Binary Masks (No Overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82603e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plain_train_net import OutputVis\n",
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_name = 'Fold 1'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "\n",
    "dfimg_dummy = RPDplt.dfimg.sort_index()\n",
    "df_unique = dfimg_dummy.iloc[::49, :]\n",
    "vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=True)\n",
    "\n",
    "for scan in range(len(df_unique.index)):\n",
    "    ImgIds = dfimg_dummy.head(49).index.values\n",
    "    vis.output_masks_to_tiff(ImgIds, dfimg_dummy.loc[ImgIds[0],\"ptid\"], dfimg_dummy.loc[ImgIds[0], \"eye\"])\n",
    "    dfimg_dummy = dfimg_dummy.iloc[49:]\n",
    "    if dfimg_dummy.empty:\n",
    "        #print('DataFrame is empty!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c20d3f",
   "metadata": {},
   "source": [
    "# Creating a TIF file from Binary Masks (With Overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbcfa83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39464/3837076595.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pt_OD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_overlay_masks_to_tiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pt_OD_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_unique\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pt_OS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"now here!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ssong/detectron2-rpd-yb/plain_train_net.py\u001b[0m in \u001b[0;36moutput_overlay_masks_to_tiff\u001b[0;34m(self, ImgIds, ptid, eye)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mv_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetadataCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mv_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_font_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outputs_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImgIds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_thresh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mresult_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverlay_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0massigned_colors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ssong/detectron2-rpd-yb/plain_train_net.py\u001b[0m in \u001b[0;36mget_outputs_from_file\u001b[0;34m(self, ImgId, imgsize, vis)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mBBoxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoxMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBBoxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfrom_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#0= XYXY, 1 = XYWH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0minst_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_boxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#pred_masks_rle=pred_masks_rle)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInstances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minst_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from plain_train_net import OutputVis\n",
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_name = 'Test Set'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "\n",
    "dfimg_dummy = RPDplt.dfimg.sort_index()\n",
    "df_unique = dfimg_dummy.ptid.unique()\n",
    "vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=True)\n",
    "for scan in range(len(df_unique)):\n",
    "    df_currentpt = dfimg_dummy.loc[dfimg_dummy['ptid'] == df_unique[scan]]\n",
    "    df_pt_OD = df_currentpt.loc[df_currentpt['eye'] == 'OD']\n",
    "    df_pt_OS = df_currentpt.loc[df_currentpt['eye'] == 'OS']\n",
    "    df_pt_OD_ids = df_pt_OD.index.values\n",
    "    df_pt_OS_ids = df_pt_OS.index.values\n",
    "    #print(len(df_pt_OD.index))\n",
    "    #print(len(df_pt_OS_ids))\n",
    "    if (len(df_pt_OD.index) > 0):\n",
    "        print(\"here!\")\n",
    "        vis.output_overlay_masks_to_tiff(df_pt_OD_ids, df_unique[scan], 'OD')\n",
    "    if (len(df_pt_OS.index) > 0):\n",
    "        print(\"now here!\")\n",
    "        vis.output_overlay_masks_to_tiff(df_pt_OS_ids, df_unique[scan], 'OS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4780a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       gt_instances  gt_pxs  gt_xpxs  dt_instances  dt_pxs  \\\n",
      "101002_OD_oct-000.png           0.0     0.0      0.0           0.0     0.0   \n",
      "101002_OD_oct-001.png           0.0     0.0      0.0           0.0     0.0   \n",
      "101002_OD_oct-002.png           0.0     0.0      0.0           0.0     0.0   \n",
      "101002_OD_oct-003.png           0.0     0.0      0.0           0.0     0.0   \n",
      "101002_OD_oct-004.png           0.0     0.0      0.0           0.0     0.0   \n",
      "...                             ...     ...      ...           ...     ...   \n",
      "501023_OS_oct-044.png           0.0     0.0      0.0           1.0   150.0   \n",
      "501023_OS_oct-045.png           0.0     0.0      0.0           1.0    84.0   \n",
      "501023_OS_oct-046.png           0.0     0.0      0.0           0.0     0.0   \n",
      "501023_OS_oct-047.png           0.0     0.0      0.0           0.0     0.0   \n",
      "501023_OS_oct-048.png           0.0     0.0      0.0           0.0     0.0   \n",
      "\n",
      "                       dt_xpxs    ptid eye     scan  \n",
      "101002_OD_oct-000.png      0.0  101002  OD  oct-000  \n",
      "101002_OD_oct-001.png      0.0  101002  OD  oct-001  \n",
      "101002_OD_oct-002.png      0.0  101002  OD  oct-002  \n",
      "101002_OD_oct-003.png      0.0  101002  OD  oct-003  \n",
      "101002_OD_oct-004.png      0.0  101002  OD  oct-004  \n",
      "...                        ...     ...  ..      ...  \n",
      "501023_OS_oct-044.png     27.0  501023  OS  oct-044  \n",
      "501023_OS_oct-045.png     15.0  501023  OS  oct-045  \n",
      "501023_OS_oct-046.png      0.0  501023  OS  oct-046  \n",
      "501023_OS_oct-047.png      0.0  501023  OS  oct-047  \n",
      "501023_OS_oct-048.png      0.0  501023  OS  oct-048  \n",
      "\n",
      "[13813 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "from plain_train_net import OutputVis\n",
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_name = 'Test Set'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "\n",
    "dfimg_dummy = RPDplt.dfimg.sort_index()\n",
    "df_unique = dfimg_dummy.ptid.unique()\n",
    "df_has_in = dfimg_dummy.loc[dfimg_dummy['dt_instances'] > 0 ]\n",
    "print(df_has_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a80a9",
   "metadata": {},
   "source": [
    "# Creating a TIF file from Instance Masks (With Probability Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plain_train_net import OutputVis\n",
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_name = 'Fold 1'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "\n",
    "dfimg_dummy = RPDplt.dfimg.sort_index()\n",
    "df_unique = dfimg_dummy.iloc[::49, :]\n",
    "vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=True)\n",
    "\n",
    "for scan in range(len(df_unique.index)):\n",
    "    ImgIds = dfimg_dummy.head(49).index.values\n",
    "    vis.output_instances_masks_to_tiff(ImgIds, dfimg_dummy.loc[ImgIds[0],\"ptid\"], dfimg_dummy.loc[ImgIds[0], \"eye\"])\n",
    "    dfimg_dummy = dfimg_dummy.iloc[49:]\n",
    "    if dfimg_dummy.empty:\n",
    "        #print('DataFrame is empty!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "#Opening tif file to see if it was successful\n",
    "mfile = \"extracted_test/101007_OD-bmasks.tif\"\n",
    "msk = Image.open(mfile)\n",
    "for i,page in enumerate(ImageSequence.Iterator(msk)):\n",
    "    page.save(\"msk_extracted/msk-{:03d}.png\".format(i))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72baeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "#Opening tif file to see if it was successful\n",
    "mfile = \"extracted_test_overlays/101002_OD-bmasks.tif\"\n",
    "msk = Image.open(mfile)\n",
    "for i,page in enumerate(ImageSequence.Iterator(msk)):\n",
    "    page.save(\"msk_extracted_overlays/msk-{:03d}.png\".format(i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31819cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "#Opening tif file to see if it was successful\n",
    "mfile = \"instances_mask_overlays/101002_OD-ipmasks_overlay.tif\"\n",
    "msk = Image.open(mfile)\n",
    "for i,page in enumerate(ImageSequence.Iterator(msk)):\n",
    "    page.save(\"msk_instances_overlays/msk-{:03d}.png\".format(i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from table_styles import styles\n",
    "dfpts = RPDplt.dfpts.sort_values(by=['dt_instances'],ascending=False)\n",
    "html_str = dfpts.style.format('{:.0f}').set_table_styles(styles).render()\n",
    "html_file = open(os.path.join('output_'+ dataset_name + '/dfpts_'+dataset_name+'.html'),'w')\n",
    "html_file.write(html_str)\n",
    "html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfimg = RPDplt.dfimg.sort_index()\n",
    "html_str = dfimg.style.set_table_styles(styles).render()\n",
    "html_file = open(os.path.join('output_'+ dataset_name + '/dfimg_'+dataset_name+'.html'),'w')\n",
    "html_file.write(html_str)\n",
    "html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_currentpt)\n",
    "df_pt_OD = df_currentpt.loc[df_currentpt['eye'] == 'asdsadasd']\n",
    "print(df_pt_OD)\n",
    "if (len(df_pt_OD.index) == 0 ):\n",
    "    print(\"empty! washoo!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0122a9a100fde86447053a2d82169efd56332aef873a4abfb4540bf3c983ad4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('detectron': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

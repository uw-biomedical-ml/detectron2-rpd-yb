{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600f92e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import detectron2\n",
    "from detectron2.data import DatasetCatalog,MetadataCatalog\n",
    "from plain_train_net import grab_dataset\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.engine import launch\n",
    "\n",
    "\n",
    "reprocess_results=True\n",
    "# dataset_name = \"reserves_fold1\"\n",
    "dataset_name = \"Fold 1\"\n",
    "dpi=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744bcbe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "from detectron2.config import get_cfg\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('configs/working.yaml')\n",
    "#really low iou for nms in order to separate out lesions\n",
    "# cfg.merge_from_list([\"MODEL.WEIGHTS\", \"output_valid_fold1/model_final.pth\",\n",
    "#                      \"OUTPUT_DIR\", \"output_valid_\"+ dataset_name + \"/results\"])\n",
    "#print(cfg.dump())  # print formatted configs\n",
    "print(cfg.MODEL.ROI_HEADS.dump())\n",
    "print(cfg.MODEL.WEIGHTS)\n",
    "print(cfg.OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d67fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [dataset_name]:\n",
    "    try:\n",
    "        DatasetCatalog.register(name, grab_dataset(name))\n",
    "    except:\n",
    "        print('Already registered.')\n",
    "        #do nothing\n",
    "    MetadataCatalog.get(name).thing_classes = [\"rpd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd3580",
   "metadata": {},
   "source": [
    "# Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a34aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%script false --no-raise-error\n",
    "#os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "#from torch.nn.parallel import DistributedDataParallel\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "#from plain_train_net import EvaluateClass\n",
    "from detectron2.evaluation import inference_on_dataset, COCOEvaluator\n",
    "\n",
    "def predict_func(cfg,dataset_name):\n",
    "    model = build_model(cfg)  # returns a torch.nn.Module\n",
    "    \n",
    "    # distributed = comm.get_world_size() > 1\n",
    "    # if distributed:\n",
    "    #     model = DistributedDataParallel(\n",
    "    #         model, device_ids=[comm.get_local_rank()], broadcast_buffers=False\n",
    "    #     )\n",
    "    \n",
    "    myloader = build_detection_test_loader(cfg,dataset_name) \n",
    "    myeval = COCOEvaluator(dataset_name,tasks={'bbox','segm'},output_dir =\"output_\"+ dataset_name) #produces _coco_format.json when initialized\n",
    "\n",
    "\n",
    "    for mdl in (\"fold1\", \"fold2\", \"fold3\", \"fold4\",\"fold5\"):\n",
    "        #build model\n",
    "        model_weights_path = \"/data/amd-data/cera-rpd/detectron2-rpd/output_valid_\"+ mdl +\"/model_final.pth\"\n",
    "        DetectionCheckpointer(model).load(model_weights_path);  # load a file, usually from cfg.MODEL.WEIGHTS\n",
    "        model.eval(); #set model in evaluation mode\n",
    "        myeval.reset()\n",
    "        output_dir = \"output_\"+ dataset_name + \"/\"+mdl\n",
    "        myeval._output_dir = output_dir\n",
    "        print(\"running inference on \", mdl)\n",
    "        results_i = inference_on_dataset(model, myloader, myeval) #produces coco_instance_results.json when myeval.evaluate is called\n",
    "    \n",
    "    return  \n",
    "predict_func(cfg,dataset_name)\n",
    "print(\"done predict_func\")\n",
    "# launch(\n",
    "#     predict_func,\n",
    "#     6, # of gpus\n",
    "#     num_machines=1,\n",
    "#     machine_rank=0,\n",
    "#     dist_url=\"auto\",\n",
    "#     args=(cfg,dataset_name,), #args to predict_func\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe11a1e",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cdc64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "from Ensembler import Ensembler\n",
    "ens = Ensembler('output_'+dataset_name,dataset_name,[\"fold1\", \"fold2\", \"fold3\", \"fold4\",\"fold5\"],.2)\n",
    "ens.mean_score_nms()\n",
    "ens.save_coco_instances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3207f5f1",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494d0f3",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654a72d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using previously cached COCO format annotations at 'output_Fold 1\\Fold 1_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Calculated metrics for 8616 images\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "WARNING: Scores for all iou thresholds and all recall levels are not defined. This can arise if ground truth annotations contain no instances. Leaving fpr matrix as None\n",
      "Using alternate calculation for fpr at instance score threshold of 0.5\n",
      "{'dataset': 'Fold 1', 'precision': -1.0, 'recall': 0.0, 'fpr': 0.05246053847207459, 'iou': 0.2, 'probability': 0.5}\n",
      "WARNING: Scores for all iou thresholds and all recall levels are not defined. This can arise if ground truth annotations contain no instances. Leaving fpr matrix as None\n",
      "Using alternate calculation for fpr at instance score threshold of 0.5\n"
     ]
    }
   ],
   "source": [
    "from plain_train_net import EvaluateClass,CreatePlotsRPD\n",
    "import json\n",
    "#evaluate ensemble\n",
    "myeval = EvaluateClass(\n",
    "    dataset_name, \"output_\"+ dataset_name,iou_thresh = .2,prob_thresh=0.5,evalsuper=False)\n",
    "myeval.evaluate()\n",
    "%precision 3\n",
    "print(myeval.summarize_scalars())\n",
    "with open(os.path.join(\"output_\"+ dataset_name,'scalar_dict.json'),\"w\") as outfile:\n",
    "    json.dump(obj=myeval.summarize_scalars(),fp=outfile)\n",
    "#num_images = myeval.num_images\n",
    "#myeval.plot_PRcurve()\n",
    "#plt.tight_layout()\n",
    "#myeval.plot_recall_vs_prob()\n",
    "#plt.tight_layout()\n",
    "\n",
    "RPDplt = CreatePlotsRPD.initfromcoco(myeval.mycoco,myeval.prob_thresh)\n",
    "#RPDplt.gt_dt_FP_FN_count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb05e92",
   "metadata": {},
   "source": [
    "## Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc16f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate individual models\n",
    "import json\n",
    "myeval.evalsuper=False\n",
    "for mdl in (\"fold1\", \"fold2\", \"fold3\", \"fold4\",\"fold5\"):\n",
    "    myeval.reset()\n",
    "    output_dir = \"output_\"+ dataset_name + \"/\"+mdl\n",
    "    myeval._output_dir = output_dir\n",
    "    myeval.evaluate()\n",
    "    print(myeval.summarize_scalars())\n",
    "    with open(os.path.join(output_dir,'scalar_dict.json'),\"w\") as outfile:\n",
    "        json.dump(obj=myeval.summarize_scalars(),fp=outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ad597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from table_styles import styles\n",
    "mydicts=[]\n",
    "for mdl in ['fold1','fold2','fold3','fold4','fold5']:\n",
    "    output_dir = \"output_\"+ dataset_name + \"/\"+mdl\n",
    "    with open(os.path.join(output_dir,'scalar_dict.json')) as f:\n",
    "        mydicts.append(json.load(f))\n",
    "with open(os.path.join(\"output_\"+ dataset_name,'scalar_dict.json')) as f:\n",
    "    mydicts.append(json.load(f))\n",
    "dfr = pd.DataFrame(mydicts)\n",
    "dfr = dfr.assign(fp = np.int32(dfr.fpr*num_images))\n",
    "dfr = dfr.assign(f1 = 2*(dfr.precision*dfr.recall)/(dfr.precision + dfr.recall))\n",
    "dfr = dfr.assign(model = ['1','2','3','4','5','ensemble'])\n",
    "# dfr = dfr[['model','fpr','fp','probability','dataset']]\n",
    "dfr = dfr[['model','dataset','precision','recall','f1','fpr','fp','iou','probability']]\n",
    "pd.set_option('display.precision',3)\n",
    "dfr.style.set_table_styles(styles).set_table_attributes('style=\"font-size: 17px\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a675d1",
   "metadata": {},
   "source": [
    "# Visualize Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e319005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from plain_train_net import OutputVis\n",
    "\n",
    "dataset_name = 'Fold 1'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "out_file = os.path.join(\"output_\"+ dataset_name,'mean_score_nms_'+dataset_name+'_nonrpd.pdf')\n",
    "\n",
    "# mdl = 'fold1'\n",
    "# pred_file = os.path.join(\"output_\"+ dataset_name,mdl,\"coco_instances_results.json\")\n",
    "# out_file = os.path.join(\"output_\"+ dataset_name,'mean_score_nms_'+mdl+'.pdf')\n",
    "\n",
    "# vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=False)\n",
    "# ImgIds = RPDplt.dfimg.index[RPDplt.dfimg.dt_instances>0] #np.abs(df.gt_xpxs-df.dt_xpxs).sort_values(ascending=False).index[0:50].values\n",
    "# vis.output_to_pdf(ImgIds,out_file)\n",
    "\n",
    "df = RPDplt.dfimg\n",
    "vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=True)\n",
    "ImgIds = RPDplt.dfimg.sample(50).index.values\n",
    "#ImgIds = np.abs(df.gt_xpxs-df.dt_xpxs).sort_values(ascending=False).index[0:10].values\n",
    "vis.output_to_pdf(ImgIds,out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fcddd2",
   "metadata": {},
   "source": [
    "# Creating a TIF file from Binary Masks (No Overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82603e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plain_train_net import OutputVis\n",
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_name = 'Fold 1'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "\n",
    "dfimg_dummy = RPDplt.dfimg.sort_index()\n",
    "df_unique = dfimg_dummy.iloc[::49, :]\n",
    "vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=True)\n",
    "\n",
    "for scan in range(len(df_unique.index)):\n",
    "    ImgIds = dfimg_dummy.head(49).index.values\n",
    "    vis.output_masks_to_tiff(ImgIds, dfimg_dummy.loc[ImgIds[0],\"ptid\"], dfimg_dummy.loc[ImgIds[0], \"eye\"])\n",
    "    dfimg_dummy = dfimg_dummy.iloc[49:]\n",
    "    if dfimg_dummy.empty:\n",
    "        #print('DataFrame is empty!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c20d3f",
   "metadata": {},
   "source": [
    "# Creating a TIF file from Binary Masks (With Overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfa83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plain_train_net import OutputVis\n",
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_name = 'Test Set'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "\n",
    "dfimg_dummy = RPDplt.dfimg.sort_index()\n",
    "df_unique = dfimg_dummy.ptid.unique()\n",
    "vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=True)\n",
    "for scan in range(len(df_unique)):\n",
    "    df_currentpt = dfimg_dummy.loc[dfimg_dummy['ptid'] == df_unique[scan]]\n",
    "    df_pt_OD = df_currentpt.loc[df_currentpt['eye'] == 'OD']\n",
    "    df_pt_OS = df_currentpt.loc[df_currentpt['eye'] == 'OS']\n",
    "    df_pt_OD_ids = df_pt_OD.index.values\n",
    "    df_pt_OS_ids = df_pt_OS.index.values\n",
    "    #print(len(df_pt_OD.index))\n",
    "    #print(len(df_pt_OS_ids))\n",
    "    if (len(df_pt_OD.index) > 0):\n",
    "        print(\"here!\")\n",
    "        vis.output_overlay_masks_to_tiff(df_pt_OD_ids, df_unique[scan], 'OD')\n",
    "    if (len(df_pt_OS.index) > 0):\n",
    "        print(\"now here!\")\n",
    "        vis.output_overlay_masks_to_tiff(df_pt_OS_ids, df_unique[scan], 'OS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4780a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plain_train_net import OutputVis\n",
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_name = 'Fold 1'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "\n",
    "dfimg_dummy = RPDplt.dfimg.sort_index()\n",
    "df_unique = dfimg_dummy.ptid.unique()\n",
    "df_has_in = dfimg_dummy.loc[dfimg_dummy['dt_instances'] > 0 ]\n",
    "df_has_in.to_csv(\"has_inst.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a80a9",
   "metadata": {},
   "source": [
    "# Creating a TIF file from Instance Masks (With Probability Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plain_train_net import OutputVis\n",
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_name = 'Fold 1'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "\n",
    "dfimg_dummy = RPDplt.dfimg.sort_index()\n",
    "df_unique = dfimg_dummy.iloc[::49, :]\n",
    "vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=True)\n",
    "\n",
    "for scan in range(len(df_unique.index)):\n",
    "    ImgIds = dfimg_dummy.head(49).index.values\n",
    "    vis.output_instances_masks_to_tiff(ImgIds, dfimg_dummy.loc[ImgIds[0],\"ptid\"], dfimg_dummy.loc[ImgIds[0], \"eye\"])\n",
    "    dfimg_dummy = dfimg_dummy.iloc[49:]\n",
    "    if dfimg_dummy.empty:\n",
    "        #print('DataFrame is empty!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "#Opening tif file to see if it was successful\n",
    "mfile = \"extracted_test/1130960_OD-bmasks.tif\"\n",
    "msk = Image.open(mfile)\n",
    "for i,page in enumerate(ImageSequence.Iterator(msk)):\n",
    "    page.save(\"msk_extracted/msk-{:03d}.png\".format(i))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72baeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "#Opening tif file to see if it was successful\n",
    "mfile = \"extracted_test_overlays/101088_OD-bmasks_overlay.tif\"\n",
    "msk = Image.open(mfile)\n",
    "for i,page in enumerate(ImageSequence.Iterator(msk)):\n",
    "    page.save(\"msk_extracted_overlays/msk-{:03d}.png\".format(i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31819cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps,ImageFilter,ImageSequence\n",
    "#Opening tif file to see if it was successful\n",
    "mfile = \"instances_mask_overlays/101088_OD-ipmasks_overlay.tif\"\n",
    "msk = Image.open(mfile)\n",
    "for i,page in enumerate(ImageSequence.Iterator(msk)):\n",
    "    page.save(\"msk_instances_overlays/msk-{:03d}.png\".format(i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from table_styles import styles\n",
    "dfpts = RPDplt.dfpts.sort_values(by=['dt_instances'],ascending=False)\n",
    "html_str = dfpts.style.format('{:.0f}').set_table_styles(styles).render()\n",
    "html_file = open(os.path.join('output_'+ dataset_name + '/dfpts_'+dataset_name+'.html'),'w')\n",
    "html_file.write(html_str)\n",
    "html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332195e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfimg = RPDplt.dfimg.sort_index()\n",
    "html_str = dfimg.style.set_table_styles(styles).render()\n",
    "html_file = open(os.path.join('output_'+ dataset_name + '/dfimg_'+dataset_name+'.html'),'w')\n",
    "html_file.write(html_str)\n",
    "html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28bfa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_currentpt)\n",
    "df_pt_OD = df_currentpt.loc[df_currentpt['eye'] == 'asdsadasd']\n",
    "print(df_pt_OD)\n",
    "if (len(df_pt_OD.index) == 0 ):\n",
    "    print(\"empty! washoo!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0122a9a100fde86447053a2d82169efd56332aef873a4abfb4540bf3c983ad4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('detectron': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
